{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization\n",
    "### This notebook contains the code necessary to re-create the visualizations we present in our paper.\n",
    "### All the visualization were done in Python. The structure of this notebook is as follows:\n",
    "1. Importing necessary libraries. Please see *visualization_requirements.txt* for version information.\n",
    "2. Creating the helper functions for our queries to the database.\n",
    "3. A markdown cell explaining the next block of cells.\n",
    "4. A cell containing an SQL query that collects aggregated data and writes them to an excel file\n",
    "5. Followed with cell(s) containing a visualization of the data that was collected. These cells are self-contained and can be run in any order.\n",
    "6. Empty cell and go to step 3.\n",
    "\n",
    "### Extra files needed are \"faostat_production.xlsx\" and \"grouped_food_items.xlsx\".\n",
    "\n",
    "Author: Osman Mutlu and Nehir Kızılilsoley\\\n",
    "Edited by: Osman Mutlu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colorbar as colorbar\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.ticker import LogLocator\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from d3blocks import D3Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup connection to database and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that connects to the PostgreSQL database with helper functions to execute SQL queries\n",
    "psycopg2.extensions.register_adapter(np.int64, psycopg2._psycopg.AsIs)\n",
    "\n",
    "class PostgresDatabase:\n",
    "    def __init__(self, db_host, db_port, db_name, db_user, db_password):\n",
    "        self.connection = psycopg2.connect(user = db_user,\n",
    "                                           password = db_password,\n",
    "                                           host = db_host,\n",
    "                                           port = db_port,\n",
    "                                           database = db_name)\n",
    "        self.cursor = self.connection.cursor()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()\n",
    "\n",
    "    def commit(self):\n",
    "        self.connection.commit()\n",
    "\n",
    "    def rollback(self):\n",
    "        self.connection.rollback()\n",
    "\n",
    "    def close(self, commit=False):\n",
    "        if commit:\n",
    "            self.commit()\n",
    "\n",
    "        self.cursor.close()\n",
    "        self.connection.close()\n",
    "\n",
    "    def execute(self, sql: str, params=None):\n",
    "        self.cursor.execute(sql, params or ())\n",
    "\n",
    "    def fetchall(self):\n",
    "        return self.cursor.fetchall()\n",
    "\n",
    "    def fetchone(self):\n",
    "        return self.cursor.fetchone()\n",
    "\n",
    "    def query(self, sql: str, params=None):\n",
    "        self.cursor.execute(sql, params or ())\n",
    "        return self.fetchall()\n",
    "\n",
    "    def querydf(self, sql: str, params=None) -> pd.DataFrame:\n",
    "        if params:\n",
    "            sql = self.cursor.mogrify(sql, params).decode()\n",
    "\n",
    "        return pd.read_sql_query(sql, self.connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary variables stored in .env file for database connection\n",
    "load_dotenv()\n",
    "\n",
    "# Or assign them yourself\n",
    "# DB_HOST = \"\"\n",
    "# DB_PORT = \"\"\n",
    "# DB_NAME = \"\"\n",
    "# DB_USER = \"\"\n",
    "# DB_PASSWORD = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total and positive number of measurements per contaminant (parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contaminant measurements\n",
    "\n",
    "with PostgresDatabase(os.getenv(\"DB_HOST\"), os.getenv(\"DB_PORT\"), os.getenv(\"DB_NAME\"), os.getenv(\"DB_USERNAME\"), os.getenv(\"DB_PASSWORD\")) as db:\n",
    "    out = db.query(\"select termextendedname as name, masterhierarchycode as code from ontologies_efsa.param\")\n",
    "    code_to_name = {code: name for (name, code) in out}\n",
    "    code_to_full_name = {}\n",
    "    for (_, code) in out:\n",
    "        if code is not None:\n",
    "            split_code = code.split(\".\")\n",
    "            code_to_full_name[code] = \"::\".join([code_to_name[\".\".join(split_code[:i+1])] for i in range(len(split_code))])\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT type, paramid, termextendedname AS param_name, masterhierarchycode AS full_name, total_measurements, positive_measurements\n",
    "    FROM (\n",
    "        SELECT filetype AS type, param_id AS paramid, COUNT(*) as total_measurements, COUNT(1) FILTER (WHERE evalcode_id IN (2, 9, 11, 14)) AS positive_measurements\n",
    "        FROM efsa.measurement_core\n",
    "        GROUP BY type, paramid\n",
    "    )\n",
    "    LEFT JOIN ontologies_efsa.param\n",
    "    ON paramid=ontologies_efsa.param.id\n",
    "    \"\"\"\n",
    "    df = db.querydf(query)\n",
    "    df[\"full_name\"] = df.full_name.apply(lambda x: code_to_full_name[x])\n",
    "    \n",
    "    df.to_excel(\"contaminant_measurements.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "contaminant_measurements = pd.read_excel(\"contaminant_measurements.xlsx\")\n",
    "\n",
    "\n",
    "# Separate 'full_name' into multiple columns (Lev1 to Lev8)\n",
    "df_separated = contaminant_measurements['full_name'].str.split('::', expand=True)\n",
    "df_separated.columns = [f'Lev{i+1}' for i in range(df_separated.shape[1])]\n",
    "df_separated = pd.concat([contaminant_measurements, df_separated], axis=1)\n",
    "df_separated['category'] = np.where(df_separated['Lev1'] == 'nutrients', df_separated['Lev3'], df_separated['Lev1'])\n",
    "\n",
    "\n",
    "# Summarize data by Lev1 category\n",
    "df_summary = df_separated.groupby('category').agg(\n",
    "    total_measurements=('total_measurements', 'sum'),\n",
    "    positive_measurements=('positive_measurements', 'sum')\n",
    ")\n",
    "\n",
    "df_summary['proportion_positive'] = df_summary['positive_measurements'] *100 / df_summary['total_measurements']\n",
    "df_summary = df_summary.reset_index().sort_values(by='total_measurements', ascending=False)\n",
    "\n",
    "\n",
    "df_summary['category'] = df_summary['category'].str.title()\n",
    "df_summary_category = df_summary[\n",
    "    ~df_summary['category'].str.lower().isin(['terms used for grouping purposes', 'oft term', 'not in list', 'microorganisms'])\n",
    "].copy()\n",
    "df_summary_category['category'] = df_summary_category['category'].str.replace(r'Persistent Organic Pollutants \\(Pops\\) And Other Organic Contaminants', 'POPs and Other Organic Contaminants', regex=True)\n",
    "df_summary_category['category'] = df_summary_category['category'].str.replace(r'Chemical Elements \\(Including Derivatives\\) And Others', 'Chemical Elements and Derivatives', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "##### Lev1 #####\n",
    "\n",
    "pal  = \"Reds\"\n",
    "plot_dat = df_summary_category.copy()\n",
    "\n",
    "# --- Log-scale size transformation ---\n",
    "plot_dat['log_size'] = np.log10(plot_dat['total_measurements'])\n",
    "\n",
    "# Min & max for log scale\n",
    "log_min = plot_dat['log_size'].min()\n",
    "log_max = plot_dat['log_size'].max()\n",
    "\n",
    "# --- Generate log-spaced legend values ---\n",
    "raw_min = plot_dat['total_measurements'].min()\n",
    "raw_max = plot_dat['total_measurements'].max()\n",
    "\n",
    "# Define nice, generic log-scale values\n",
    "size_legend_values = [10**3, 10**4, 10**5, 10**6, 10**7, 10**8]  \n",
    "\n",
    "# Filter to values within your actual data range\n",
    "size_legend_values = [v for v in size_legend_values if raw_min <= v <= raw_max]\n",
    "\n",
    "# Format labels nicely\n",
    "labels = [f\"{int(v):,}\" for v in size_legend_values]\n",
    "\n",
    "\n",
    "# --- Scale function for circle sizes ---\n",
    "def scale_size(val, vmin, vmax, smin=50, smax=400):\n",
    "    return smin + (val - vmin) / (vmax - vmin) * (smax - smin)\n",
    "\n",
    "# --- Create size legend handles ---\n",
    "legend_handles = [\n",
    "    plt.scatter([], [], \n",
    "                s=scale_size(np.log10(val), log_min, log_max), \n",
    "                label=label,\n",
    "                color='gray', \n",
    "                alpha=0.6, \n",
    "                edgecolors='black')\n",
    "    for val, label in zip(size_legend_values, labels)\n",
    "]\n",
    "\n",
    "# --- Plot separate size legend ---\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.legend(\n",
    "    handles=legend_handles, \n",
    "    title=\"Total Measurements\", \n",
    "    scatterpoints=1, \n",
    "    frameon=False,\n",
    "    labelspacing=1.2, \n",
    "    loc='center'\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('contaminant_Lev1_legend.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create a dummy colorbar using the same colormap and normalization\n",
    "fig, ax = plt.subplots(figsize=(0.5, 6))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "norm = mcolors.Normalize(\n",
    "    vmin=plot_dat['proportion_positive'].min(), \n",
    "    vmax=plot_dat['proportion_positive'].max()\n",
    ")\n",
    "cbar = colorbar.ColorbarBase(\n",
    "    ax, cmap=pal, norm=norm, orientation='vertical'\n",
    ")\n",
    "cbar.set_label('Measurements above limits (%)')\n",
    "plt.savefig('contaminant_Lev1_cbar.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Plot main bubble chart ---\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.grid(True, zorder=0, alpha = 0.5)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=plot_dat,\n",
    "    x='proportion_positive', \n",
    "    y='category', \n",
    "    hue='proportion_positive',\n",
    "    size='log_size',\n",
    "    sizes=(50, 400), \n",
    "    palette=pal,\n",
    "    zorder=3,\n",
    "    edgecolor='black',  \n",
    "    linewidth=0.7,\n",
    "    legend=False\n",
    ")\n",
    "# Hardcoded text annotations\n",
    "annotations = [\n",
    "    {\"text\": \"297 Million\", \"x\": 0.12, \"y\": \"Pesticides\"},\n",
    "    {\"text\": \"75 Million\", \"x\": 0.1, \"y\": \"Pharmacologically Active Substances\"},\n",
    "    {\"text\": \"17 Million\", \"x\": 0.22, \"y\": \"POPs and Other Organic Contaminants\"},\n",
    "    {\"text\": \"1.6 Million\", \"x\": 0.68, \"y\": \"Toxins\"},\n",
    "    {\"text\": \"1 Million\", \"x\": 0.85, \"y\": \"Chemical Elements and Derivatives\"},\n",
    "    {\"text\": \"0.3 Million\", \"x\": 0.8, \"y\": \"Process Contaminants\"},\n",
    "    {\"text\": \"59,179\", \"x\": 0.15, \"y\": \"Botanicals\"},\n",
    "    {\"text\": \"13,574\", \"x\": 0.27, \"y\": \"Erucic Acid\"},\n",
    "    {\"text\": \"5,663\", \"x\": 0.65, \"y\": \"Food Contact Materials\"},\n",
    "    {\"text\": \"4,045\", \"x\": 0.35, \"y\": \"Food Additives\"},\n",
    "]\n",
    "\n",
    "\n",
    "for ann in annotations:\n",
    "    plt.text(\n",
    "        ann[\"x\"], \n",
    "        ann[\"y\"], \n",
    "        ann[\"text\"], \n",
    "        ha='left', \n",
    "        va='center',\n",
    "        fontsize=9,\n",
    "        color='dimgray',\n",
    "        alpha=1\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title('The first level of contaminant hierarchies')\n",
    "plt.xlabel('Measurements above limits (%)')  # or just rename to 'Proportion Positive (%)' if more accurate\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig('contaminant_Lev1.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "##### Lev2 #####\n",
    "\n",
    "toxins = df_separated[df_separated['Lev1'].str.lower() == 'toxins'].groupby('Lev2').agg(\n",
    "    total_measurements=('total_measurements', 'sum'),\n",
    "    positive_measurements=('positive_measurements', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "toxins['proportion_positive'] = toxins['positive_measurements'] / toxins['total_measurements']\n",
    "toxins = toxins.reset_index().sort_values(by='total_measurements', ascending=False)\n",
    "toxins['Lev2'] = toxins['Lev2'].str.title()\n",
    "\n",
    "\n",
    "\n",
    "# Create a bubble plot with the legend outside and grid enabled\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.grid(True, zorder=0)\n",
    "sns.scatterplot(\n",
    "    x='proportion_positive', \n",
    "    y='Lev2', \n",
    "    size='total_measurements', \n",
    "    hue='proportion_positive', \n",
    "    sizes=(50, 600), \n",
    "    data=toxins,\n",
    "    palette='coolwarm',\n",
    "    zorder=3,\n",
    "    edgecolor='black',  \n",
    "    linewidth=0.7  \n",
    ")\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Toxins')\n",
    "plt.xlabel('Proportion of Positive Measurements')\n",
    "plt.ylabel('Category')\n",
    "\n",
    "# Move the legend outside the plot\n",
    "plt.legend(title='', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('contaminant_Lev2toxins.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "pops = df_separated[\n",
    "    df_separated['Lev1'].str.lower() == 'persistent organic pollutants (pops) and other organic contaminants'\n",
    "].groupby('Lev2').agg(\n",
    "    total_measurements=('total_measurements', 'sum'),\n",
    "    positive_measurements=('positive_measurements', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "pops['proportion_positive'] = pops['positive_measurements'] / pops['total_measurements']\n",
    "pops = pops.reset_index().sort_values(by='total_measurements', ascending=False)\n",
    "pops['Lev2'] = pops['Lev2'].str.title()\n",
    "\n",
    "\n",
    "# Create a bubble plot with the legend outside and grid enabled\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.grid(True, zorder=0)\n",
    "sns.scatterplot(\n",
    "    x='proportion_positive', \n",
    "    y='Lev2', \n",
    "    size='total_measurements', \n",
    "    hue='proportion_positive', \n",
    "    sizes=(50, 600), \n",
    "    data=pops,\n",
    "    palette='coolwarm',\n",
    "    zorder=3,\n",
    "    edgecolor='black',  \n",
    "    linewidth=0.7  \n",
    ")\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Persistent Organic Pollutants (POPs) and other organic contaminants')\n",
    "plt.xlabel('Proportion of Positive Measurements')\n",
    "plt.ylabel('Category')\n",
    "\n",
    "# Move the legend outside the plot\n",
    "plt.legend(title='', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('contaminant_Lev2pops.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "heavies = [\n",
    "    \"lead and derivatives\", \"cadmium and derivatives\", \"mercury and derivatives\",\n",
    "    \"arsenic and derivatives\", \"nickel and derivatives\", \"copper and derivatives\",\n",
    "    \"zinc and derivatives\", \"chromium and derivatives\", \"selenium and derivatives\",\n",
    "    \"manganese and derivatives\", \"tin and derivatives\", \"thallium and derivatives\",\n",
    "    \"barium and derivatives\", \"cobalt and derivatives\", \"antimony and derivatives\",\n",
    "    \"silver and derivatives\", \"beryllium and derivatives\", \"vanadium and derivatives\",\n",
    "    \"uranium and derivatives\", \"thorium and derivatives\"\n",
    "]\n",
    "\n",
    "chems = df_separated[\n",
    "    df_separated['Lev1'].str.lower() == 'chemical elements (including derivatives) and others'\n",
    "]\n",
    "\n",
    "chems = chems[chems['Lev2'].isin(heavies)].groupby('Lev2').agg(\n",
    "    total_measurements=('total_measurements', 'sum'),\n",
    "    positive_measurements=('positive_measurements', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "chems['proportion_positive'] = chems['positive_measurements'] / chems['total_measurements']\n",
    "chems = chems.reset_index().sort_values(by='total_measurements', ascending=False)\n",
    "chems['Lev2'] = chems['Lev2'].str.title()\n",
    "\n",
    "\n",
    "# Create a bubble plot with the legend outside and grid enabled\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.grid(True, zorder=0)\n",
    "sns.scatterplot(\n",
    "    x='proportion_positive', \n",
    "    y='Lev2', \n",
    "    size='total_measurements', \n",
    "    hue='proportion_positive', \n",
    "    sizes=(50, 600), \n",
    "    data=chems,\n",
    "    palette='coolwarm',\n",
    "    zorder=3,\n",
    "    edgecolor='black',  \n",
    "    linewidth=0.7  \n",
    ")\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Chemical Elements (Including Derivatives) and Others')\n",
    "plt.xlabel('Proportion of Positive Measurements')\n",
    "plt.ylabel('Category')\n",
    "\n",
    "# Move the legend outside the plot\n",
    "plt.legend(title='', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('contaminant_Lev2chems.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamin = pd.read_excel(\"contaminant_measurements.xlsx\")\n",
    "\n",
    "# Summarize the data\n",
    "summ = (\n",
    "    contamin.groupby([\"type\", \"param_name\"])\n",
    "    .agg(\n",
    "        total_meas=(\"total_measurements\", \"sum\"),\n",
    "        pos_meas=(\"positive_measurements\", \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Add percentage column\n",
    "summ[\"percentage\"] = (summ[\"pos_meas\"] / summ[\"total_meas\"]) * 100\n",
    "title_dict = [\"Chemical contaminants\", \"Pesticide residues\", \"VMPRs\"]\n",
    "\n",
    "formatter0 = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter0.set_scientific(True)\n",
    "formatter0.set_powerlimits((-2, 2))\n",
    "\n",
    "formatter1 = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter1.set_scientific(True)\n",
    "formatter1.set_powerlimits((-2, 2))\n",
    "\n",
    "\n",
    "#%%\n",
    "def plot_top_contaminants(contamin, ind, context=\"paper\", style=\"ticks\", figsize=(7, 3)):\n",
    "\n",
    "    # Filter only VMPR and select top 10 contaminants\n",
    "    var = pd.unique(summ['type'])[ind] #array(['chemical', 'pesticides', 'vmpr'], dtype=object)\n",
    "\n",
    "    df = (\n",
    "        summ[summ[\"type\"] == var]\n",
    "        .nlargest(10, \"total_meas\")  # Select top 10 by total_meas\n",
    "        .copy()\n",
    "    )\n",
    "    df['param_name'] = df['param_name'].str.title()\n",
    "\n",
    "    # Set style and context\n",
    "    sns.set_style(style)\n",
    "    sns.set_context(context)\n",
    "\n",
    "    # Set color palette\n",
    "    pal = sns.color_palette(\"tab10\")\n",
    "    color_total = pal[ind]\n",
    "    color_pos = pal[ind]\n",
    "\n",
    "    # Create figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize, sharey=True)\n",
    "\n",
    "    # Total Measurements Bar Plot\n",
    "    sns.barplot(\n",
    "        data=df,\n",
    "        x=\"total_meas\",\n",
    "        y=\"param_name\",\n",
    "        color=color_total,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.5,\n",
    "        ax=axes[0]\n",
    "    )\n",
    "\n",
    "    axes[0].set_title(\"Total measurements\", fontsize=11)\n",
    "    axes[0].set_xlabel(\"Count\", fontsize=9)\n",
    "    axes[0].set_ylabel(title_dict[ind], fontsize=9)\n",
    "    axes[0].tick_params(axis='both', which='major', labelsize=9)\n",
    "    axes[0].xaxis.set_major_formatter(formatter0)\n",
    "    axes[0].grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Positive Measurements Bar Plot\n",
    "    sns.barplot(\n",
    "        data=df,\n",
    "        x=\"pos_meas\",\n",
    "        y=\"param_name\",\n",
    "        color=color_pos,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.5,\n",
    "        ax=axes[1]\n",
    "    )\n",
    "\n",
    "    axes[1].set_title(\"Measurements above limits\", fontsize=11)\n",
    "    axes[1].set_xlabel(\"Count\", fontsize=9)\n",
    "    axes[1].set_ylabel(\"\")\n",
    "    axes[1].tick_params(axis='both', which='major', labelsize=9)\n",
    "    axes[1].grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    axes[1].xaxis.set_major_formatter(formatter1)\n",
    "\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'contaminant_stats_bar_{var}.png', dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for x in range(3):\n",
    "    plot_top_contaminants(contamin, x)\n",
    "\n",
    "\n",
    "\n",
    "def plot_all_top_contaminants(summ, title_dict):\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"paper\")\n",
    "\n",
    "    pal = sns.color_palette(\"tab10\")\n",
    "    types = ['chemical', 'pesticides', 'vmpr']\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(7, 8), sharey='row')\n",
    "\n",
    "    for i, var in enumerate(types):\n",
    "        df = (\n",
    "            summ[summ[\"type\"] == var]\n",
    "            .nlargest(10, \"total_meas\")\n",
    "            .copy()\n",
    "        )\n",
    "        df['param_name'] = df['param_name'].str.title()\n",
    "\n",
    "        color = pal[i]\n",
    "        formatter0 = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter0.set_scientific(True)\n",
    "        formatter0.set_powerlimits((-2, 2))\n",
    "        formatter1 = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter1.set_scientific(True)\n",
    "        formatter1.set_powerlimits((-2, 2))\n",
    "        # Total measurements\n",
    "        sns.barplot(\n",
    "            data=df,\n",
    "            x=\"total_meas\",\n",
    "            y=\"param_name\",\n",
    "            color=color,\n",
    "            edgecolor=\"white\",\n",
    "            linewidth=1.5,\n",
    "            ax=axes[i, 0]\n",
    "        )\n",
    "        axes[i, 0].set_title(\"Total measurements\", fontsize=9, weight='bold')\n",
    "        axes[i, 0].set_ylabel(title_dict[i], fontsize=10, weight='bold')\n",
    "        axes[i, 0].set_xlabel(\"\")\n",
    "        axes[i, 0].xaxis.set_major_formatter(formatter0)\n",
    "        axes[i, 0].tick_params(labelsize=8)\n",
    "        axes[i, 0].grid(axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Add percentage labels to the end of each bar\n",
    "        for j, (val, total) in enumerate(zip(df['pos_meas'], df['total_meas'])):\n",
    "            pct = val / total * 100 if total > 0 else 0\n",
    "            axes[i, 1].text(\n",
    "                val + 0.01 * df['pos_meas'].max(),  # x-pos\n",
    "                j,                                  # y-pos\n",
    "                f\"{pct:.2f}%\",                      \n",
    "                va='center',\n",
    "                ha='left',\n",
    "                fontsize=7,\n",
    "                color='black'\n",
    "            )\n",
    "\n",
    "        # Positive measurements\n",
    "        sns.barplot(\n",
    "            data=df,\n",
    "            x=\"pos_meas\",\n",
    "            y=\"param_name\",\n",
    "            color=color,\n",
    "            edgecolor=\"white\",\n",
    "            linewidth=1.5,\n",
    "            ax=axes[i, 1]\n",
    "        )\n",
    "        axes[i, 1].set_title(\"Measurements above limits\", fontsize=9, weight='bold')\n",
    "        axes[i, 1].set_ylabel(\"\")\n",
    "        axes[i, 1].set_xlabel(\"\")\n",
    "        axes[i, 1].xaxis.set_major_formatter(formatter1)\n",
    "        axes[i, 1].tick_params(labelsize=8)\n",
    "        axes[i, 1].grid(axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "    sns.despine()\n",
    "    fig.align_ylabels()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"combined_contaminants_barplot.png\", dpi=1200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_all_top_contaminants(summ, title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total and positive number of contaminants per product per sampling strategy (either all, per year, per sampling country, or per origin country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contaminants per product including sampling strategy\n",
    "\n",
    "with PostgresDatabase(os.getenv(\"DB_HOST\"), os.getenv(\"DB_PORT\"), os.getenv(\"DB_NAME\"), os.getenv(\"DB_USERNAME\"), os.getenv(\"DB_PASSWORD\")) as db:\n",
    "    # Collect product info\n",
    "    query = \"\"\"\n",
    "    SELECT t1.id AS product_id, t2.termextendedname AS matrix_product_name, t2.prodclasshierarchycode AS matrix_hierarchy,\n",
    "        t3.termextendedname AS mtx_product_name, t3.masterhierarchycode AS mtx_hierarchy\n",
    "    FROM ontologies_efsa.product_catalogue AS t1\n",
    "    LEFT JOIN ontologies_efsa.matrix AS t2\n",
    "        ON t1.matrix_id=t2.id\n",
    "    LEFT JOIN ontologies_efsa.mtx AS t3\n",
    "        ON t1.mtx_id=t3.id\n",
    "    \"\"\"\n",
    "    product_df = db.querydf(query)\n",
    "    # matrix\n",
    "    out = db.query(\"select termextendedname as name, prodclasshierarchycode as code from ontologies_efsa.matrix\")\n",
    "    code_to_name = {code: name for (name, code) in out}\n",
    "    code_to_full_name = {}\n",
    "    for (_, code) in out:\n",
    "        if code is not None:\n",
    "            split_code = code.split(\".\")\n",
    "            code_to_full_name[code] = \"matrix::\" + \"::\".join([code_to_name[\".\".join(split_code[:i+1])] for i in range(len(split_code))])\n",
    "    product_df[\"matrix_full_name\"] = product_df.matrix_hierarchy.apply(lambda x: code_to_full_name[x] if x is not None else None)\n",
    "\n",
    "    # mtx\n",
    "    out = db.query(\"select termextendedname as name, masterhierarchycode as code from ontologies_efsa.mtx\")\n",
    "    code_to_name = {code: name for (name, code) in out}\n",
    "    code_to_full_name = {}\n",
    "    for (_, code) in out:\n",
    "        if code is not None:\n",
    "            split_code = code.split(\".\")\n",
    "            code_to_full_name[code] = \"mtx::\" + \"::\".join([code_to_name[\".\".join(split_code[:i+1])] for i in range(len(split_code))])\n",
    "\n",
    "    product_df[\"mtx_full_name\"] = product_df.mtx_hierarchy.apply(lambda x: code_to_full_name[x] if x is not None else None)\n",
    "\n",
    "    # combine\n",
    "    product_df[\"full_name\"] = product_df.matrix_full_name.combine_first(product_df.mtx_full_name)\n",
    "    product_df.matrix_product_name = \"matrix::\" + product_df.matrix_product_name\n",
    "    product_df.mtx_product_name = \"mtx::\" + product_df.mtx_product_name\n",
    "    product_df[\"product_name\"] = product_df.matrix_product_name.combine_first(product_df.mtx_product_name)\n",
    "    product_df.loc[product_df.full_name.isna(), \"full_name\"] = product_df.loc[product_df.full_name.isna(), \"product_name\"]\n",
    "    product_df = product_df[[\"product_id\", \"product_name\", \"full_name\"]]\n",
    "\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT t3.termextendedname AS samp_strategy, t2.product_id AS product_id, t1.filetype AS type, COUNT(*) AS total_measurements, COUNT(1) FILTER (WHERE t1.evalcode_id IN (2, 9, 11, 14)) AS positive_measurements\n",
    "    FROM efsa.measurement_core AS t1\n",
    "    LEFT JOIN efsa.sample_core AS t2\n",
    "        ON t1.sample_core_id=t2.id\n",
    "    LEFT JOIN ontologies_efsa.sampstr as t3\n",
    "        ON t2.sampstr_id=t3.id\n",
    "    GROUP BY samp_strategy, product_id, type\n",
    "    \"\"\"\n",
    "    df = db.querydf(query)\n",
    "    df = df.merge(product_df, on=\"product_id\", how=\"left\")\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT t3.termextendedname AS samp_strategy, t2.product_id AS product_id, t1.filetype AS type, t2.sampy AS year, COUNT(*) AS total_measurements,\n",
    "        COUNT(1) FILTER (WHERE t1.evalcode_id IN (2, 9, 11, 14)) AS positive_measurements\n",
    "    FROM efsa.measurement_core AS t1\n",
    "    LEFT JOIN efsa.sample_core AS t2\n",
    "        ON t1.sample_core_id=t2.id\n",
    "    LEFT JOIN ontologies_efsa.sampstr as t3\n",
    "        ON t2.sampstr_id=t3.id\n",
    "    GROUP BY samp_strategy, product_id, type, year\n",
    "    \"\"\"\n",
    "    yearly_df = db.querydf(query)\n",
    "    yearly_df = yearly_df.merge(product_df, on=\"product_id\", how=\"left\")\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT t4.termextendedname AS samp_strategy, t2.product_id AS product_id, t1.filetype AS type, t3.termextendedname AS samp_country,\n",
    "        COUNT(*) AS total_measurements, COUNT(1) FILTER (WHERE t1.evalcode_id IN (2, 9, 11, 14)) AS positive_measurements\n",
    "    FROM efsa.measurement_core AS t1\n",
    "    LEFT JOIN efsa.sample_core AS t2\n",
    "        ON t1.sample_core_id=t2.id\n",
    "    LEFT JOIN ontologies_efsa.country AS t3\n",
    "        ON t2.sampcountry_id=t3.id\n",
    "    LEFT JOIN ontologies_efsa.sampstr as t4\n",
    "        ON t2.sampstr_id=t4.id\n",
    "    GROUP BY samp_country, samp_strategy, product_id, type\n",
    "    \"\"\"\n",
    "    samp_df = db.querydf(query)\n",
    "    samp_df = samp_df.merge(product_df, on=\"product_id\", how=\"left\")\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT t4.termextendedname AS samp_strategy, t2.product_id AS product_id, t1.filetype AS type, t3.termextendedname AS orig_country,\n",
    "        COUNT(*) AS total_measurements, COUNT(1) FILTER (WHERE t1.evalcode_id IN (2, 9, 11, 14)) AS positive_measurements\n",
    "    FROM efsa.measurement_core AS t1\n",
    "    LEFT JOIN efsa.sample_core AS t2\n",
    "        ON t1.sample_core_id=t2.id\n",
    "    LEFT JOIN ontologies_efsa.country AS t3\n",
    "        ON t2.origcountry_id=t3.id\n",
    "    LEFT JOIN ontologies_efsa.sampstr as t4\n",
    "        ON t2.sampstr_id=t4.id\n",
    "    GROUP BY orig_country, samp_strategy, product_id, type\n",
    "    \"\"\"\n",
    "    orig_df = db.querydf(query)\n",
    "    orig_df = orig_df.merge(product_df, on=\"product_id\", how=\"left\")\n",
    "\n",
    "    with pd.ExcelWriter('sampling_strategy_based_positive_contaminants_per_product.xlsx') as writer:\n",
    "        df.to_excel(writer, sheet_name='distribution', index=False)\n",
    "        yearly_df.to_excel(writer, sheet_name='yearly distribution', index=False)\n",
    "        samp_df.to_excel(writer, sheet_name='samp country distribution', index=False)\n",
    "        orig_df.to_excel(writer, sheet_name='orig country distribution', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean\n",
    "country_dist = pd.read_excel(\"sampling_strategy_based_positive_contaminants_per_product.xlsx\",\n",
    "                             sheet_name=\"samp country distribution\")\n",
    "country_dist[\"samp_country\"] = country_dist[\"samp_country\"].str.title()\n",
    "\n",
    "# Consistent strategy order\n",
    "strategy_order = ['objective sampling', 'selective sampling', 'suspect sampling', \n",
    "                  'convenient sampling', 'other']\n",
    "\n",
    "# Types and color palettes\n",
    "types = [\"chemical\", \"pesticides\", \"vmpr\"]\n",
    "type_titles = [\"Chemical contaminants\", \"Pesticide residues\", \"VMPRs\"]\n",
    "\n",
    "# Dictionary to store all plot-ready data\n",
    "plot_data = {}\n",
    "\n",
    "for type_val in types:\n",
    "    # --- 1. Filter data by type\n",
    "    df_type = country_dist[country_dist[\"type\"] == type_val].copy()\n",
    "\n",
    "    # --- 2. Get total measurements per country\n",
    "    country_totals = df_type.groupby(\"samp_country\")[\"total_measurements\"].sum()\n",
    "    top_countries = country_totals.sort_values(ascending=False).head(15).index.tolist()\n",
    "\n",
    "    # --- 3. Subset to top countries\n",
    "    df_type_top = df_type[df_type[\"samp_country\"].isin(top_countries)].copy()\n",
    "\n",
    "    # --- 4. Aggregate total and positive measurements per country\n",
    "    totals_df = df_type_top.groupby(\"samp_country\").agg(\n",
    "        total_meas=(\"total_measurements\", \"sum\"),\n",
    "        pos_meas=(\"positive_measurements\", \"sum\")\n",
    "    )\n",
    "\n",
    "    # --- 5. Get sampling strategy totals per country\n",
    "    strat_df = df_type_top.groupby([\"samp_country\", \"samp_strategy\"])[\"total_measurements\"].sum().unstack(fill_value=0)\n",
    "    strat_df = strat_df.reindex(columns=strategy_order, fill_value=0)\n",
    "\n",
    "    # --- 6. Normalize strategy counts to 100% per country\n",
    "    strat_normalized = strat_df.div(strat_df.sum(axis=1), axis=0)\n",
    "\n",
    "    # --- 7. Combine everything\n",
    "    combined = totals_df.join(strat_normalized)\n",
    "    combined = combined.loc[top_countries]  # enforce order\n",
    "\n",
    "    # --- 8. Store in dictionary for plotting\n",
    "    plot_data[type_val] = {\n",
    "        \"data\": combined,\n",
    "        \"title\": type_titles[types.index(type_val)]\n",
    "    }\n",
    "\n",
    "# === Setup\n",
    "fig, axes = plt.subplots(3, 3, figsize=(13, 10), sharey=False)\n",
    "pal2 = sns.color_palette(\"tab10\")\n",
    "\n",
    "# Color mapping for strategies (must match order)\n",
    "strategy_order = ['objective sampling', 'selective sampling', 'suspect sampling', \n",
    "                  'convenient sampling', 'other']\n",
    "strategy_colors = {\n",
    "    'objective sampling': '#1f77b4',\n",
    "    'selective sampling': '#ff7f0e',\n",
    "    'suspect sampling': '#9467bd',\n",
    "    'convenient sampling': '#2ca02c',\n",
    "    'other': '#8c564b'\n",
    "}\n",
    "\n",
    "# Formatters\n",
    "formatter0 = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter0.set_scientific(True)\n",
    "formatter0.set_powerlimits((-2, 2))\n",
    "\n",
    "formatter1 = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter1.set_scientific(True)\n",
    "formatter1.set_powerlimits((-2, 2))\n",
    "\n",
    "# === Loop over types\n",
    "for i, (type_val, content) in enumerate(plot_data.items()):\n",
    "    df = content[\"data\"]\n",
    "    title = content[\"title\"]\n",
    "    countries = df.index.tolist()\n",
    "\n",
    "    # --- Column 1: Total measurements\n",
    "    sns.barplot(\n",
    "        y=countries,\n",
    "        x=\"total_meas\",\n",
    "        data=df.reset_index(),\n",
    "        color=pal2[i],\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.5,\n",
    "        ax=axes[i, 0]\n",
    "    )\n",
    "    axes[i, 0].set_title(f\"{title} - Total measurements\", fontsize=9, weight='bold')\n",
    "    axes[i, 0].set_ylabel(\"\")\n",
    "    axes[i, 0].set_xlabel(\"\")\n",
    "    axes[i, 0].xaxis.set_major_formatter(formatter0)\n",
    "    axes[i, 0].tick_params(labelsize=8)\n",
    "    axes[i, 0].grid(axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # --- Column 2: Positive measurements with %\n",
    "    sns.barplot(\n",
    "        y=countries,\n",
    "        x=\"pos_meas\",\n",
    "        data=df.reset_index(),\n",
    "        color=pal2[i],\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.5,\n",
    "        ax=axes[i, 1]\n",
    "    )\n",
    "    for j, (val, total) in enumerate(zip(df[\"pos_meas\"], df[\"total_meas\"])):\n",
    "        pct = val / total * 100 if total > 0 else 0\n",
    "        axes[i, 1].text(\n",
    "            val + 0.01 * df[\"pos_meas\"].max(),\n",
    "            j,\n",
    "            f\"{pct:.2f}%\",\n",
    "            va='center',\n",
    "            ha='left',\n",
    "            fontsize=8,\n",
    "            color='black'\n",
    "        )\n",
    "    axes[i, 1].set_title(\"Measurements above limits\", fontsize=9, weight='bold')\n",
    "    axes[i, 1].set_ylabel(\"\")\n",
    "    axes[i, 1].set_xlabel(\"\")\n",
    "    axes[i, 1].xaxis.set_major_formatter(formatter1)\n",
    "    axes[i, 1].tick_params(labelsize=8)\n",
    "    axes[i, 1].grid(axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # --- Column 3: 100% stacked sampling strategy\n",
    "    df_reversed = df.iloc[::-1]\n",
    "    bottom = np.zeros(len(df_reversed))\n",
    "    for strat in strategy_order:\n",
    "        axes[i, 2].barh(\n",
    "            df_reversed.index,\n",
    "            df_reversed[strat],\n",
    "            left=bottom,\n",
    "            height=0.8,\n",
    "            label=strat,\n",
    "            color=strategy_colors[strat]\n",
    "        )\n",
    "        bottom += df_reversed[strat].values\n",
    "\n",
    "    axes[i, 2].set_title(\"Sampling Strategy Share\", fontsize=9, weight='bold')\n",
    "    axes[i, 2].set_xlabel(\"\")\n",
    "    axes[i, 2].set_ylabel(\"\")\n",
    "    axes[i, 2].tick_params(labelsize=8)\n",
    "    axes[i, 2].grid(axis='x', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        axes[i, 2].legend(title='Strategy', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "\n",
    "# === Final formatting\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"final_typewise_top15_plot.png\", dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total and positive number of contaminants per product (either all, per year, per sampling country, or per origin country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contaminants per product\n",
    "\n",
    "with PostgresDatabase(os.getenv(\"DB_HOST\"), os.getenv(\"DB_PORT\"), os.getenv(\"DB_NAME\"), os.getenv(\"DB_USERNAME\"), os.getenv(\"DB_PASSWORD\")) as db:\n",
    "    # Collect product info\n",
    "    query = \"\"\"\n",
    "    SELECT t1.id AS product_id, t2.termextendedname AS matrix_product_name, t2.prodclasshierarchycode AS matrix_hierarchy,\n",
    "        t3.termextendedname AS mtx_product_name, t3.masterhierarchycode AS mtx_hierarchy\n",
    "    FROM ontologies_efsa.product_catalogue AS t1\n",
    "    LEFT JOIN ontologies_efsa.matrix AS t2\n",
    "        ON t1.matrix_id=t2.id\n",
    "    LEFT JOIN ontologies_efsa.mtx AS t3\n",
    "        ON t1.mtx_id=t3.id\n",
    "    \"\"\"\n",
    "    product_df = db.querydf(query)\n",
    "    # matrix\n",
    "    out = db.query(\"select termextendedname as name, prodclasshierarchycode as code from ontologies_efsa.matrix\")\n",
    "    code_to_name = {code: name for (name, code) in out}\n",
    "    code_to_full_name = {}\n",
    "    for (_, code) in out:\n",
    "        if code is not None:\n",
    "            split_code = code.split(\".\")\n",
    "            code_to_full_name[code] = \"matrix::\" + \"::\".join([code_to_name[\".\".join(split_code[:i+1])] for i in range(len(split_code))])\n",
    "    product_df[\"matrix_full_name\"] = product_df.matrix_hierarchy.apply(lambda x: code_to_full_name[x] if x is not None else None)\n",
    "\n",
    "    # mtx\n",
    "    out = db.query(\"select termextendedname as name, masterhierarchycode as code from ontologies_efsa.mtx\")\n",
    "    code_to_name = {code: name for (name, code) in out}\n",
    "    code_to_full_name = {}\n",
    "    for (_, code) in out:\n",
    "        if code is not None:\n",
    "            split_code = code.split(\".\")\n",
    "            code_to_full_name[code] = \"mtx::\" + \"::\".join([code_to_name[\".\".join(split_code[:i+1])] for i in range(len(split_code))])\n",
    "\n",
    "    product_df[\"mtx_full_name\"] = product_df.mtx_hierarchy.apply(lambda x: code_to_full_name[x] if x is not None else None)\n",
    "\n",
    "    # combine\n",
    "    product_df[\"full_name\"] = product_df.matrix_full_name.combine_first(product_df.mtx_full_name)\n",
    "    product_df.matrix_product_name = \"matrix::\" + product_df.matrix_product_name\n",
    "    product_df.mtx_product_name = \"mtx::\" + product_df.mtx_product_name\n",
    "    product_df[\"product_name\"] = product_df.matrix_product_name.combine_first(product_df.mtx_product_name)\n",
    "    product_df.loc[product_df.full_name.isna(), \"full_name\"] = product_df.loc[product_df.full_name.isna(), \"product_name\"]\n",
    "    product_df = product_df[[\"product_id\", \"product_name\", \"full_name\"]]\n",
    "\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT t2.product_id AS product_id, t1.filetype AS type, COUNT(*) AS total_measurements, COUNT(1) FILTER (WHERE t1.evalcode_id IN (2, 9, 11, 14)) AS positive_measurements\n",
    "    FROM efsa.measurement_core AS t1\n",
    "    LEFT JOIN efsa.sample_core AS t2\n",
    "        ON t1.sample_core_id=t2.id\n",
    "    GROUP BY product_id, type\n",
    "    \"\"\"\n",
    "    df = db.querydf(query)\n",
    "    df = df.merge(product_df, on=\"product_id\", how=\"left\")\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT t2.product_id AS product_id, t1.filetype AS type, t2.sampy AS year, COUNT(*) AS total_measurements,\n",
    "        COUNT(1) FILTER (WHERE t1.evalcode_id IN (2, 9, 11, 14)) AS positive_measurements\n",
    "    FROM efsa.measurement_core AS t1\n",
    "    LEFT JOIN efsa.sample_core AS t2\n",
    "        ON t1.sample_core_id=t2.id\n",
    "    GROUP BY product_id, type, year\n",
    "    \"\"\"\n",
    "    yearly_df = db.querydf(query)\n",
    "    yearly_df = yearly_df.merge(product_df, on=\"product_id\", how=\"left\")\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT t2.product_id AS product_id, t1.filetype AS type, t3.termextendedname AS samp_country,\n",
    "        COUNT(*) AS total_measurements, COUNT(1) FILTER (WHERE t1.evalcode_id IN (2, 9, 11, 14)) AS positive_measurements\n",
    "    FROM efsa.measurement_core AS t1\n",
    "    LEFT JOIN efsa.sample_core AS t2\n",
    "        ON t1.sample_core_id=t2.id\n",
    "    LEFT JOIN ontologies_efsa.country AS t3\n",
    "        ON t2.sampcountry_id=t3.id\n",
    "    GROUP BY samp_country, product_id, type\n",
    "    \"\"\"\n",
    "    samp_df = db.querydf(query)\n",
    "    samp_df = samp_df.merge(product_df, on=\"product_id\", how=\"left\")\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT t2.product_id AS product_id, t1.filetype AS type, t3.termextendedname AS orig_country,\n",
    "        COUNT(*) AS total_measurements, COUNT(1) FILTER (WHERE t1.evalcode_id IN (2, 9, 11, 14)) AS positive_measurements\n",
    "    FROM efsa.measurement_core AS t1\n",
    "    LEFT JOIN efsa.sample_core AS t2\n",
    "        ON t1.sample_core_id=t2.id\n",
    "    LEFT JOIN ontologies_efsa.country AS t3\n",
    "        ON t2.origcountry_id=t3.id\n",
    "    GROUP BY orig_country, product_id, type\n",
    "    \"\"\"\n",
    "    orig_df = db.querydf(query)\n",
    "    orig_df = orig_df.merge(product_df, on=\"product_id\", how=\"left\")\n",
    "\n",
    "    with pd.ExcelWriter('positive_contaminants_per_product.xlsx') as writer:\n",
    "        df.to_excel(writer, sheet_name='distribution', index=False)\n",
    "        yearly_df.to_excel(writer, sheet_name='yearly distribution', index=False)\n",
    "        samp_df.to_excel(writer, sheet_name='samp country distribution', index=False)\n",
    "        orig_df.to_excel(writer, sheet_name='orig country distribution', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel files\n",
    "country_dist = pd.read_excel(\"positive_contaminants_per_product.xlsx\", sheet_name=\"samp country distribution\")\n",
    "faostat = pd.read_excel(\"extra_files/faostat_production.xlsx\")\n",
    "# Rename columns in faostat\n",
    "faostat = faostat.rename(columns={\"value\": \"productionFAO\", \"area\": \"samp_country\"})\n",
    "faostat = faostat[(faostat[\"year\"] >= 2000) & (faostat[\"year\"] <= 2024)]\n",
    "\n",
    "country_dist[\"samp_country\"] = country_dist[\"samp_country\"].str.title()\n",
    "faostat[\"samp_country\"] = faostat[\"samp_country\"].str.title()\n",
    "\n",
    "\n",
    "# Summarize country_dist data by type and country\n",
    "country_meas_df = country_dist.groupby([\"type\", \"samp_country\"]).agg(\n",
    "    total_meas=(\"total_measurements\", \"sum\"),\n",
    "    pos_meas=(\"positive_measurements\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "country_meas_df[\"percentage\"] = (country_meas_df[\"pos_meas\"] / country_meas_df[\"total_meas\"]) * 100\n",
    "\n",
    "# Create top country list\n",
    "top_countries = (\n",
    "    country_meas_df.groupby(\"samp_country\")\n",
    "    .agg(total_meas_sum=(\"total_meas\", \"sum\"))\n",
    "    .sort_values(\"total_meas_sum\", ascending=False)\n",
    "    # .head(28)\n",
    "    .reset_index()\n",
    ")\n",
    "# top_countries[\"order\"] = range(len(top_countries))  \n",
    "\n",
    "# Filter and reorder country_meas_df\n",
    "filtered_df = country_meas_df[country_meas_df[\"samp_country\"].isin(top_countries[\"samp_country\"])]\n",
    "\n",
    "# Merge total production data into filtered_df and reorder\n",
    "fao_summ = faostat.groupby(\"samp_country\").agg(\n",
    "    total_production=(\"productionFAO\", lambda x: x.sum(skipna=True))\n",
    ").reset_index()\n",
    "\n",
    "# Merge in FAO production\n",
    "summary_df = top_countries.merge(\n",
    "    fao_summ, on=\"samp_country\", how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "formatter0 = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter0.set_scientific(True)\n",
    "formatter0.set_powerlimits((-2, 2))\n",
    "\n",
    "formatter1 = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter1.set_scientific(True)\n",
    "formatter1.set_powerlimits((-2, 2))\n",
    "\n",
    "#%%\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 7), sharex=True)\n",
    "    # Set style and context\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "pal = sns.color_palette(\"tab20\", n_colors=len(summary_df))\n",
    "\n",
    "# Total Measurements Bar Plot\n",
    "sns.barplot(\n",
    "        data=summary_df,\n",
    "        x=\"samp_country\",\n",
    "        y=\"total_meas_sum\",\n",
    "        palette=pal,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.5,\n",
    "        ax=axes[0]\n",
    "    )\n",
    "axes[0].set_title(\"Total measurements\", fontsize=11)\n",
    "axes[0].set_xlabel(\" \", fontsize=9)\n",
    "axes[0].set_ylabel(\"Number of measurements\", fontsize=9)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=9)\n",
    "axes[0].yaxis.set_major_formatter(formatter0)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Positive Measurements Bar Plot\n",
    "sns.barplot(\n",
    "        data=summary_df,\n",
    "        x=\"samp_country\",\n",
    "        y=\"total_production\",\n",
    "        palette=pal,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.5,\n",
    "        ax=axes[1]\n",
    "    )\n",
    "axes[1].set_title(\"Total production (FAO)\", fontsize=11)\n",
    "axes[1].set_xlabel(\" \", fontsize=9)\n",
    "axes[1].set_ylabel(\"Tonnes\")\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=9)\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "axes[1].yaxis.set_major_formatter(formatter1)\n",
    "axes[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('country_stats_FAO.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#%%\n",
    "def create_combined_df(filtered_df, top_countries):\n",
    "    types = filtered_df[\"type\"].unique()\n",
    "    countries = top_countries[\"samp_country\"].unique()\n",
    "\n",
    "    combined_data = []\n",
    "    for country in countries:\n",
    "        country_data = {\"samp_country\": country}\n",
    "        for type_val in types:\n",
    "            type_df = filtered_df[(filtered_df[\"type\"] == type_val) & (filtered_df[\"samp_country\"] == country)]\n",
    "            if not type_df.empty:\n",
    "                country_data[f\"{type_val}_total\"] = type_df[\"total_meas\"].iloc[0]\n",
    "                country_data[f\"{type_val}_pos\"] = type_df[\"pos_meas\"].iloc[0]\n",
    "            else:\n",
    "                country_data[f\"{type_val}_total\"] = 0  # or NaN, depending on preference\n",
    "                country_data[f\"{type_val}_pos\"] = 0    # or NaN, depending on preference\n",
    "        combined_data.append(country_data)\n",
    "\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "    combined_df[\"samp_country\"] = pd.Categorical(combined_df[\"samp_country\"], categories=countries, ordered=True)\n",
    "    combined_df = combined_df.sort_values(by=\"samp_country\") #sort to ensure proper order.\n",
    "    return combined_df\n",
    "\n",
    "# Example usage (assuming you have filtered_df and top_countries defined):\n",
    "combined_df = create_combined_df(filtered_df, top_countries)\n",
    "\n",
    "types = [\"chemical\", \"pesticides\", \"vmpr\"]\n",
    "tit = [\"Chemical contaminants\", \"Pesticide residues\", \"VMPRs\"]\n",
    "pal2 = sns.color_palette(\"tab10\")\n",
    "\n",
    "combined_df = combined_df.iloc[0:15,:].reset_index(drop=True)\n",
    "combined_df[\"samp_country\"] = pd.Categorical(\n",
    "    combined_df[\"samp_country\"],\n",
    "    categories=combined_df[\"samp_country\"].tolist(),  # use only the 20\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "\n",
    "# Create subplots in a 3x2 grid\n",
    "fig, axes = plt.subplots(3, 2, figsize=(7, 10), sharey=True)\n",
    "\n",
    "for i, type_val in enumerate(types):\n",
    "    formatter0 = mticker.ScalarFormatter(useMathText=True)\n",
    "    formatter0.set_scientific(True)\n",
    "    formatter0.set_powerlimits((-2, 2))\n",
    "    formatter1 = mticker.ScalarFormatter(useMathText=True)\n",
    "    formatter1.set_scientific(True)\n",
    "    formatter1.set_powerlimits((-2, 2))\n",
    "    # Total measurements\n",
    "    sns.barplot(\n",
    "        data=combined_df,\n",
    "        y=\"samp_country\",\n",
    "        x=f\"{type_val}_total\",\n",
    "        color=pal2[i],\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.5,\n",
    "        ax=axes[i, 0]\n",
    "    )\n",
    "    axes[i, 0].set_title(f\"{tit[i]} - Total measurements\", fontsize=9, weight='bold')\n",
    "    axes[i, 0].set_ylabel(\"\", fontsize=11, weight='bold')\n",
    "    axes[i, 0].set_xlabel(\"\")\n",
    "    axes[i, 0].xaxis.set_major_formatter(formatter0)\n",
    "    axes[i, 0].tick_params(labelsize=8)\n",
    "    axes[i, 0].grid(axis='x', linestyle='--', alpha=0.5)\n",
    "    axes[i, 0].tick_params(axis='y') \n",
    "\n",
    "    sns.barplot(\n",
    "        data=combined_df,\n",
    "        y=\"samp_country\",\n",
    "        x=f\"{type_val}_pos\",\n",
    "        color=pal2[i],\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.5,\n",
    "        ax=axes[i, 1]\n",
    "    )\n",
    "\n",
    "    # Add percentage labels to the end of each bar\n",
    "    for j, (val, total) in enumerate(zip(combined_df[f\"{type_val}_pos\"], combined_df[f\"{type_val}_total\"])):\n",
    "        pct = val / total * 100 if total > 0 else 0\n",
    "        axes[i, 1].text(\n",
    "            val + 0.01 * combined_df[f\"{type_val}_pos\"].max(),  # x-pos\n",
    "            j,                                  # y-pos\n",
    "            f\"{pct:.2f}%\",                      \n",
    "            va='center',\n",
    "            ha='left',\n",
    "            fontsize=8,\n",
    "            color='black'\n",
    "        )\n",
    "    axes[i, 1].set_title(f\"Measurements above limits\", fontsize=9, weight='bold')\n",
    "    axes[i, 1].set_ylabel(\"\", fontsize=11, weight='bold')\n",
    "    axes[i, 1].set_xlabel(\"\")\n",
    "    axes[i, 1].xaxis.set_major_formatter(formatter1)\n",
    "    axes[i, 1].tick_params(labelsize=8)\n",
    "    axes[i, 1].grid(axis='x', linestyle='--', alpha=0.5)\n",
    "    axes[i, 1].tick_params(axis='y') \n",
    "\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('country_stats_total_positive_combined.png', dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"positive_contaminants_per_product.xlsx\"\n",
    "\n",
    "food_measurements = pd.read_excel(file_path)\n",
    "\n",
    "# Separate the 'full_name' column into multiple columns\n",
    "df_separated = food_measurements['full_name'].str.split('::', expand=True)\n",
    "# Rename the new columns (similar to Lev1 to Lev12 in R)\n",
    "df_separated.columns = [f'Lev{i+1}' for i in range(df_separated.shape[1])]\n",
    "# Concatenate the separated columns back to the original DataFrame\n",
    "df_separated = pd.concat([food_measurements, df_separated], axis=1)\n",
    "\n",
    "\n",
    "# Apply the logic to create the 'result' column\n",
    "def create_result(row):\n",
    "    if row['type'] == \"pesticides\" and row['Lev2'] == \"all lists\" and row['Lev3'] == \"food\" and row['Lev4'] == \"plant commodities (rpcs)\" and row['Lev5'] == \"fruit rpcs\":\n",
    "        return row['Lev5']\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"all lists\" and row['Lev3'] == \"food\" and row['Lev4'] == \"plant commodities (rpcs)\" and row['Lev5'] != \"fruit rpcs\":\n",
    "        return row['Lev5']     \n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"all lists\" and row['Lev3'] == \"food\" and (row['Lev4'] not in [\"plant commodities (rpcs)\"] or pd.isna(row['Lev4'])) and not pd.isna(row['Lev5']):\n",
    "        return row['Lev5']\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"all lists\" and row['Lev3'] == \"food\" and (row['Lev4'] not in [\"plant commodities (rpcs)\"]) and pd.isna(row['Lev5']):\n",
    "        return f\"Other {row['Lev4']}\"\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"all lists\" and row['Lev3'] == \"feed\":\n",
    "        return row['Lev3']\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"all lists\" and row['Lev3'] not in [\"food\", \"feed\"]:\n",
    "        return f\"Other {row['Lev3']}\"\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"animal products\":\n",
    "        return row['Lev3']\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"cereals\" and not pd.isna(row['Lev3']):\n",
    "        return row['Lev3']\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"cereals\" and pd.isna(row['Lev3']):\n",
    "        return row['Lev2']\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"fruits and nuts, vegetables and other plant products\" and not pd.isna(row['Lev4']):\n",
    "        return row['Lev4']\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] == \"fruits and nuts, vegetables and other plant products\" and pd.isna(row['Lev4']):\n",
    "        return f\"Other {row['Lev2']}\"\n",
    "    elif row['type'] == \"pesticides\" and row['Lev2'] not in [\"all lists\", \"animal products\", \"cereals\", \"fruits and nuts, vegetables and other plant products\"]:\n",
    "        return row['Lev2']\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif row['type'] == \"chemical\" and row['Lev3'] == \"food\" and row['Lev4'] == \"plant commodities (rpcs)\":\n",
    "        return row['Lev5']\n",
    "    elif row['type'] == \"chemical\" and row['Lev3'] == \"food\" and row['Lev4'] != \"plant commodities (rpcs)\" and not pd.isna(row['Lev5']):\n",
    "        return row['Lev5']\n",
    "    elif row['type'] == \"chemical\" and row['Lev3'] == \"food\" and row['Lev4'] != \"plant commodities (rpcs)\" and pd.isna(row['Lev5']):\n",
    "        return f\"Other {row['Lev4']}\"\n",
    "    elif row['type'] == \"chemical\" and row['Lev3'] == \"feed\":\n",
    "        return row['Lev3']\n",
    "    elif row['type'] == \"chemical\" and row['Lev3'] not in [\"food\", \"feed\"]:\n",
    "        return f\"Other {row['Lev4']}\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif row['type'] == \"vmpr\" and row['Lev3'] == \"food\" and not pd.isna(row['Lev5']):\n",
    "        return row['Lev5']\n",
    "    elif row['type'] == \"vmpr\" and row['Lev3'] == \"food\" and pd.isna(row['Lev5']):\n",
    "        return row['Lev4']\n",
    "    elif row['type'] == \"vmpr\" and row['Lev3'] == \"feed\":\n",
    "        return row['Lev3']\n",
    "    elif row['type'] == \"vmpr\" and row['Lev3'] == \"facets\":\n",
    "        return row['Lev3']\n",
    "    elif row['type'] == \"vmpr\" and row['Lev3'] == \"non-food matrices\":\n",
    "        return row['Lev3']\n",
    "    elif row['type'] == \"vmpr\" and row['Lev3'] not in [\"food\", \"feed\", \"facets\", \"non-food matrices\"]:\n",
    "        return \"Other VMPR\"\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "df2 = df_separated.copy()\n",
    "df2['result'] = df2.apply(create_result, axis=1)\n",
    "\n",
    "# Summarize data by category\n",
    "df_summary2 = df2.groupby(['type', 'result']).agg(\n",
    "    total_measurements=pd.NamedAgg(column='total_measurements', aggfunc='sum'),\n",
    "    positive_measurements=pd.NamedAgg(column='positive_measurements', aggfunc='sum')\n",
    ").reset_index()\n",
    "\n",
    "df_summary2['proportion_positive'] = df_summary2['positive_measurements'] / df_summary2['total_measurements']\n",
    "df_summary2 = df_summary2.sort_values(by='total_measurements', ascending=False)\n",
    "df_summary2 = df_summary2.dropna(subset=['result']) # Equivalent to na.omit(df_summary2)\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "category_df = pd.read_excel(\"extra_files/grouped_food_items.xlsx\")\n",
    "\n",
    "# Build the mapping dictionary\n",
    "CATEGORY_MAPPING = {}\n",
    "for _, row in category_df.iterrows():\n",
    "    item = row['Item'].strip().lower()\n",
    "    category = row['Category'].strip()\n",
    "    CATEGORY_MAPPING[item] = category\n",
    "\n",
    "def assign_category(row):\n",
    "    result = row['result']\n",
    "    if pd.isna(result):\n",
    "        return result\n",
    "    result_lower = result.lower()\n",
    "    for item, category in CATEGORY_MAPPING.items():\n",
    "        if item in result_lower:\n",
    "            return category\n",
    "    return result\n",
    "\n",
    "\n",
    "df = df_summary2.copy()\n",
    "df['category'] = df.apply(assign_category, axis=1)\n",
    "\n",
    "df_grouped = df.groupby(['type', 'category']).agg(\n",
    "    total_measurements=pd.NamedAgg(column='total_measurements', aggfunc='sum'),\n",
    "    positive_measurements=pd.NamedAgg(column='positive_measurements', aggfunc='sum'),\n",
    ").reset_index()\n",
    "\n",
    "# Capitalize the first letter of the category\n",
    "df_grouped['category'] = df_grouped['category'].str[0].str.upper() + df_grouped['category'].str[1:]\n",
    "df_grouped = df_grouped.sort_values(by='total_measurements', ascending=False)\n",
    "df_grouped['proportion_positive'] = df_grouped['positive_measurements'] / df_grouped['total_measurements']\n",
    "\n",
    "\n",
    "\n",
    "title_dict = [\"Chemical contaminants\", \"Pesticide residues\", \"VMPRs\"]\n",
    "type_list = sorted(df_grouped[\"type\"].unique())\n",
    "\n",
    "def plot_all_top_contaminants(food, context=\"paper\", style=\"ticks\", figsize=(9, 12)):\n",
    "    toy = food.dropna()\n",
    "\n",
    "    sns.set_style(style)\n",
    "    sns.set_context(context)\n",
    "\n",
    "    pal = sns.color_palette(\"tab10\")\n",
    "\n",
    "    # Setup figure with 3 rows (for each 'type'), 2 columns (total vs positive)\n",
    "    fig, axes = plt.subplots(3, 2, figsize=figsize, sharey='row')\n",
    "\n",
    "    for ind, var in enumerate(type_list):\n",
    "        # var = pd.unique(toy['type'])[ind]\n",
    "        df = toy[toy[\"type\"] == var].copy()\n",
    "\n",
    "    # Capitalize and filter top 10\n",
    "        df['category'] = df['category'].str.title()\n",
    "        # df = df.nlargest(10, \"total_measurements\").copy()\n",
    "        df['category'] = pd.Categorical(df['category'], categories=df['category'].unique()[::-1], ordered=True)\n",
    "\n",
    "        color_total = pal[ind]\n",
    "        color_pos = pal[ind]\n",
    "        formatter0 = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter0.set_scientific(True)\n",
    "        formatter0.set_powerlimits((-2, 2))\n",
    "        formatter1 = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter1.set_scientific(True)\n",
    "        formatter1.set_powerlimits((-2, 2))\n",
    "    \n",
    "        # TOTAL Measurements\n",
    "        sns.barplot(\n",
    "            data=df,\n",
    "            x=\"total_measurements\",\n",
    "            y=\"category\",\n",
    "            color=color_total,\n",
    "            edgecolor=\"white\",\n",
    "            linewidth=1.5,\n",
    "            ax=axes[ind, 0]\n",
    "        )\n",
    "        axes[ind, 0].set_title(f\"{title_dict[ind]} – Total measurements\", fontsize=9, weight='bold')\n",
    "        axes[ind, 0].set_xscale(\"log\")\n",
    "        axes[ind, 0].set_xlabel(\"\")\n",
    "        axes[ind, 0].set_ylabel(\"\" if ind > 0 else \" \", fontsize=8)\n",
    "        axes[ind, 0].tick_params(axis='both', which='major', labelsize=8)\n",
    "        axes[ind, 0].xaxis.set_major_formatter(formatter0)\n",
    "        axes[ind, 0].grid(True, which='both', axis='x', linestyle='--', alpha=0.4)\n",
    "        axes[ind, 0].xaxis.set_major_locator(LogLocator(base=10.0, subs=(1.0,), numticks=10))\n",
    "        axes[ind, 0].xaxis.set_minor_locator(LogLocator(base=10.0, subs=np.arange(2, 10) * 0.1, numticks=10))\n",
    "        axes[ind, 0].tick_params(which='minor', length=3)\n",
    "        axes[ind, 0].invert_yaxis() \n",
    "\n",
    "\n",
    "        # POSITIVE Measurements\n",
    "        sns.barplot(\n",
    "            data=df,\n",
    "            x=\"positive_measurements\",\n",
    "            y=\"category\",\n",
    "            color=color_pos,\n",
    "            edgecolor=\"white\",\n",
    "            linewidth=1.5,\n",
    "            ax=axes[ind, 1]\n",
    "        )\n",
    "        # Add percentage labels\n",
    "        for cat, pos_val, total_val in zip(df['category'], df['positive_measurements'], df['total_measurements']):\n",
    "            if total_val > 0 and pos_val > 0:\n",
    "                pct = pos_val / total_val * 100\n",
    "                axes[ind, 1].text(\n",
    "                    pos_val + 0.001 * df['positive_measurements'].max(),\n",
    "                    cat,\n",
    "                    f\"{pct:.2f}%\",\n",
    "                    va='center',\n",
    "                    ha='left',\n",
    "                    fontsize=7,\n",
    "                    color='black'\n",
    "                )\n",
    "\n",
    "        axes[ind, 1].set_title(f\"Measurements above limits\", fontsize=9, weight='bold')\n",
    "        axes[ind, 1].set_xscale(\"log\")\n",
    "        axes[ind, 1].set_xlabel(\"\")\n",
    "        axes[ind, 1].set_ylabel(\"\")\n",
    "        axes[ind, 1].tick_params(axis='both', which='major', labelsize=8)\n",
    "        axes[ind, 1].xaxis.set_major_formatter(formatter1)\n",
    "        axes[ind, 1].grid(True, which='both', axis='x', linestyle='--', alpha=0.4)\n",
    "        axes[ind, 1].xaxis.set_major_locator(LogLocator(base=10.0, subs=(1.0,), numticks=10))\n",
    "        axes[ind, 1].xaxis.set_minor_locator(LogLocator(base=10.0, subs=np.arange(2, 10) * 0.1, numticks=10))\n",
    "        axes[ind, 1].tick_params(which='minor', length=3)\n",
    "        axes[ind, 1].invert_yaxis() \n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"all_bar_food_groupings.png\", dpi=1200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "plot_all_top_contaminants(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamin = pd.read_excel(\"positive_contaminants_per_product.xlsx\", sheet_name=\"yearly distribution\")\n",
    "\n",
    "# Summarize the data\n",
    "summ = (\n",
    "    contamin.groupby([\"type\", \"year\"])\n",
    "    .agg(\n",
    "        total_meas=(\"total_measurements\", \"sum\"),\n",
    "        pos_meas=(\"positive_measurements\", \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Add percentage column\n",
    "summ[\"percentage\"] = (summ[\"pos_meas\"] / summ[\"total_meas\"]) * 100\n",
    "summ = summ.drop(summ[summ['year'].isin([1970, 1998, 1999, 2107])].index)\n",
    "\n",
    "pal = sns.color_palette(\"tab10\")\n",
    "formatter0 = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter0.set_scientific(True)\n",
    "formatter0.set_powerlimits((-2, 2))\n",
    "\n",
    "formatter1 = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter1.set_scientific(True)\n",
    "formatter1.set_powerlimits((-2, 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the figure with two subplots and shared x-axis\n",
    "chem = summ[summ['type'] == 'chemical']\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 6), sharex=True)\n",
    "\n",
    "# Plot total measurements on the first subplot (axes[0])\n",
    "axes[0].plot(chem['year'], chem['total_meas'], \n",
    "             marker='o', \n",
    "             linestyle='-', \n",
    "             color = pal[0], \n",
    "             linewidth = 2)\n",
    "axes[0].set_title('Chemical contaminants', fontsize=14)\n",
    "axes[0].set_ylabel('Total measurements', fontsize=12)\n",
    "axes[0].grid(True, linestyle='--', alpha=.5)\n",
    "axes[0].xaxis.set_major_locator(mticker.MaxNLocator(nbins='auto', integer=True, prune=None))\n",
    "axes[0].tick_params(axis='both', labelsize=11)\n",
    "axes[0].yaxis.set_major_formatter(formatter0)\n",
    "\n",
    "\n",
    "axes[1].plot(chem['year'], chem['pos_meas'], \n",
    "             marker='o', \n",
    "             linestyle='-', \n",
    "             color = pal[0], \n",
    "             linewidth = 2)\n",
    "axes[1].set_title('')\n",
    "axes[1].set_ylabel('Measurements above limits', fontsize=12)\n",
    "axes[1].grid(True, linestyle='--', alpha=.5)\n",
    "axes[1].xaxis.set_major_locator(mticker.MaxNLocator(nbins='auto', integer=True, prune=None))\n",
    "axes[1].set_xlabel('Year', fontsize=12) \n",
    "axes[1].tick_params(axis='both', labelsize=11)\n",
    "# axes[1].set_xticks(chem['year'].unique())\n",
    "axes[1].yaxis.set_major_formatter(formatter1)\n",
    "\n",
    "fig.align_ylabels(axes)\n",
    "plt.setp(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('yearly_dist_lineplot_chem.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the figure with two subplots and shared x-axis\n",
    "pest = summ[summ['type'] == 'pesticides']\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 6), sharex=True)\n",
    "\n",
    "# Plot total measurements on the first subplot (axes[0])\n",
    "axes[0].plot(pest['year'], pest['total_meas'], \n",
    "             marker='o', \n",
    "             linestyle='-', \n",
    "             color = pal[1], \n",
    "             linewidth = 2)\n",
    "axes[0].set_title('Pesticide residues', fontsize=14)\n",
    "axes[0].set_ylabel('Total measurements', fontsize=12)\n",
    "axes[0].grid(True, linestyle='--', alpha=.5)\n",
    "axes[0].xaxis.set_major_locator(mticker.MaxNLocator(nbins='auto', integer=True, prune=None))\n",
    "axes[0].tick_params(axis='both', labelsize=11)\n",
    "axes[0].yaxis.set_major_formatter(formatter0)\n",
    "\n",
    "\n",
    "# Plot positive measurements on the second subplot (axes[1])\n",
    "axes[1].plot(pest['year'], pest['pos_meas'], \n",
    "             marker='o', \n",
    "             linestyle='-', \n",
    "             color = pal[1], \n",
    "             linewidth = 2)\n",
    "axes[1].set_title('')\n",
    "axes[1].set_ylabel('Measurements above limits', fontsize=12)\n",
    "axes[1].grid(True, linestyle='--', alpha=.5)\n",
    "axes[1].xaxis.set_major_locator(mticker.MaxNLocator(nbins='auto', integer=True, prune=None))\n",
    "axes[1].set_xlabel('Year', fontsize=12) \n",
    "axes[1].tick_params(axis='both', labelsize=11)\n",
    "# axes[1].set_xticks(pest['year'].unique())\n",
    "axes[1].yaxis.set_major_formatter(formatter1)\n",
    "\n",
    "fig.align_ylabels(axes)\n",
    "plt.setp(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('yearly_dist_lineplot_pest.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the figure with two subplots and shared x-axis\n",
    "vmpr = summ[summ['type'] == 'vmpr']\n",
    "vmpr = vmpr.drop(vmpr[vmpr['year'] == 2107].index)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6,6), sharex=True)\n",
    "\n",
    "axes[0].plot(vmpr['year'], vmpr['total_meas'], \n",
    "             marker='o', \n",
    "             linestyle='-', \n",
    "             color = pal[2],\n",
    "             linewidth = 2)\n",
    "axes[0].set_title('VMPRs', fontsize = 14)\n",
    "axes[0].set_ylabel('Total measurements', fontsize = 12)\n",
    "axes[0].grid(True, linestyle='--', alpha=.5)\n",
    "axes[0].xaxis.set_major_locator(mticker.MaxNLocator(nbins='auto', integer=True, prune=None))\n",
    "axes[0].tick_params(axis='both', labelsize=11)\n",
    "axes[0].yaxis.set_major_formatter(formatter0)\n",
    "\n",
    "\n",
    "axes[1].plot(vmpr['year'], vmpr['pos_meas'], \n",
    "             marker='o', \n",
    "             linestyle='-', \n",
    "             color = pal[2],\n",
    "             linewidth = 2)\n",
    "axes[1].set_title('')\n",
    "axes[1].set_ylabel('Measurements above limits', fontsize=12)\n",
    "axes[1].grid(True, linestyle='--', alpha=.5)\n",
    "axes[1].xaxis.set_major_locator(mticker.MaxNLocator(nbins='auto', integer=True, prune=None))\n",
    "axes[1].set_xlabel('Year', fontsize=12) \n",
    "axes[1].tick_params(axis='both', labelsize=11)\n",
    "# axes[1].set_xticks(vmpr['year'].unique())\n",
    "axes[1].yaxis.set_major_formatter(formatter1)\n",
    "\n",
    "fig.align_ylabels(axes)\n",
    "plt.setp(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('yearly_dist_lineplot_vmpr.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom legend labels\n",
    "colors = pal[:3]\n",
    "labels = ['Chemical contaminants', 'Pesticide residues', 'VMPRs']\n",
    "\n",
    "# Create patch handles\n",
    "legend_handles = [Patch(facecolor=pal[i], edgecolor='black', label=labels[i]) for i in range(3)]\n",
    "\n",
    "# Create a separate legend figure\n",
    "fig, ax = plt.subplots(figsize=(3, 1))  \n",
    "ax.axis('off')  \n",
    "legend = ax.legend(handles=legend_handles, \n",
    "                   loc='center', \n",
    "                   frameon=False, \n",
    "                   ncol=1, \n",
    "                   fontsize=12)\n",
    "\n",
    "plt.savefig(\"GENERAL_legends.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total and positive number of measurements per origin and sampling countries (all or per year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origin, sampling countries distribution\n",
    "\n",
    "with PostgresDatabase(os.getenv(\"DB_HOST\"), os.getenv(\"DB_PORT\"), os.getenv(\"DB_NAME\"), os.getenv(\"DB_USERNAME\"), os.getenv(\"DB_PASSWORD\")) as db:\n",
    "    # Samples grouped by original country, sampling country, and year\n",
    "    query = \"SELECT origcountry_id AS orig_country, sampcountry_id AS samp_country, sampy AS year, count(*) AS number_of_samples FROM efsa.sample_core GROUP BY orig_country, samp_country, year ORDER BY orig_country, samp_country, year ASC\"\n",
    "    df = db.querydf(query)\n",
    "    df.loc[df.orig_country.isna(), \"orig_country\"] = 9999\n",
    "\n",
    "    query = \"SELECT id, termextendedname FROM ontologies_efsa.country\"\n",
    "    country_id_to_name = {id: name for (id, name) in db.query(query)}\n",
    "    country_id_to_name[9999] = \"unknown\"\n",
    "    \n",
    "    df.orig_country = df.orig_country.apply(lambda x: country_id_to_name[x])\n",
    "    df.samp_country = df.samp_country.apply(lambda x: country_id_to_name[x])\n",
    "\n",
    "\n",
    "    # Samples with at least one above legal limit measurement\n",
    "    query = \"\"\"\n",
    "    SELECT t1.origcountry_id AS orig_country, t1.sampcountry_id AS samp_country, t1.sampy AS year, count(*) AS number_of_samples\n",
    "    FROM efsa.sample_core AS t1\n",
    "    INNER JOIN (SELECT sample_core_id FROM efsa.measurement_core WHERE evalcode_id IN (2, 9, 11, 14) GROUP BY sample_core_id) AS t2\n",
    "        ON t1.id=t2.sample_core_id\n",
    "    GROUP BY orig_country, samp_country, year\n",
    "    ORDER BY orig_country, samp_country, year ASC\n",
    "    \"\"\"\n",
    "    pos_df = db.querydf(query)\n",
    "    pos_df.loc[pos_df.orig_country.isna(), \"orig_country\"] = 9999\n",
    "    pos_df.orig_country = pos_df.orig_country.apply(lambda x: country_id_to_name[x])\n",
    "    pos_df.samp_country = pos_df.samp_country.apply(lambda x: country_id_to_name[x])\n",
    "\n",
    "    all_df = df.groupby(by=[\"orig_country\", \"samp_country\"], as_index=False).number_of_samples.sum()\n",
    "    all_pos_df = pos_df.groupby(by=[\"orig_country\", \"samp_country\"], as_index=False).number_of_samples.sum()\n",
    "    with pd.ExcelWriter('original_sampling_country.xlsx') as writer:\n",
    "        all_df.to_excel(writer, sheet_name='distribution')\n",
    "        df.to_excel(writer, sheet_name=\"yearly distribution\")\n",
    "        all_pos_df.to_excel(writer, sheet_name='pos distribution')\n",
    "        pos_df.to_excel(writer, sheet_name=\"pos yearly distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_excel(\"original_sampling_country.xlsx\", sheet_name=\"yearly distribution\", index_col=0)\n",
    "positive_data = pd.read_excel(\"original_sampling_country.xlsx\", sheet_name=\"pos yearly distribution\", index_col=0)\n",
    "positive_data = positive_data.rename(columns={'number_of_samples': 'pos_number_of_samples'})\n",
    "\n",
    "data = data.drop(data[data['year'].isin([1970, 1998, 1999, 2107])].index)\n",
    "positive_data = positive_data.drop(positive_data[positive_data['year'].isin([1970, 1998, 1999, 2107])].index)\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = data.merge(positive_data, on=['orig_country', 'samp_country', 'year'], how='left')\n",
    "merged_data['pos_number_of_samples'] = merged_data['pos_number_of_samples'].fillna(0)\n",
    "# Sum across years for same (origin, sampling) country pairs\n",
    "merged_data = merged_data.groupby(['orig_country', 'samp_country'], as_index=False).agg({\n",
    "    'number_of_samples': 'sum',\n",
    "    'pos_number_of_samples': 'sum'\n",
    "})\n",
    "\n",
    "# Recalculate positive ratio after aggregation\n",
    "merged_data['positive_ratio'] = merged_data['pos_number_of_samples'] / merged_data['number_of_samples']\n",
    "merged_data['orig_country'] = merged_data['orig_country'].str.title()\n",
    "merged_data['samp_country'] = merged_data['samp_country'].str.title()\n",
    "\n",
    "\n",
    "\n",
    "# Assuming merged_data is already loaded and merged\n",
    "sample_counts = merged_data['number_of_samples']\n",
    "\n",
    "# Parameters\n",
    "top_n = 20\n",
    "ord = 'positive_ratio' #'positive_ratio' or \"number_of_samples\"\n",
    "sample_cutoff = 5000\n",
    "\n",
    "\n",
    "# Filter data\n",
    "filtered_data = merged_data[\n",
    "    (merged_data['orig_country'] != merged_data['samp_country']) & \n",
    "    (merged_data['number_of_samples'] > sample_cutoff)\n",
    "]\n",
    "filtered_data = filtered_data.nlargest(top_n, ord)\n",
    "\n",
    "# Prepare chord diagram data\n",
    "chord_data = filtered_data[['orig_country', 'samp_country', 'number_of_samples']].copy()\n",
    "chord_data.columns = ['source', 'target', 'weight']  # Directly use D3Blocks' expected names\n",
    "\n",
    "\n",
    "\n",
    "tit = f\"chord_diag_top{top_n}count_top{sample_cutoff}samp_order{ord}\"\n",
    "\n",
    "# Store positive ratios for each edge\n",
    "edge_ratios = filtered_data[['orig_country', 'samp_country', 'positive_ratio']].copy()\n",
    "edge_ratios.columns = ['source', 'target', 'positive_ratio']\n",
    "\n",
    "# Create chord diagram\n",
    "d3 = D3Blocks()\n",
    "d3.chord(\n",
    "    chord_data,\n",
    "    filepath=f'{tit}.html',\n",
    "    title= tit,\n",
    "    figsize = [600,600],\n",
    "    fontsize=12,\n",
    "    arrowhead=20,\n",
    "    cmap='tab20',  # This applies to nodes only\n",
    "    notebook=False\n",
    ")\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=256):\n",
    "    \"\"\"Returns a truncated colormap from cmap between minval and maxval\"\"\"\n",
    "    new_cmap = LinearSegmentedColormap.from_list(\n",
    "        f'trunc({cmap.name},{minval:.2f},{maxval:.2f})',\n",
    "        cmap(np.linspace(minval, maxval, n))\n",
    "    )\n",
    "    return new_cmap\n",
    "\n",
    "# Normalize and map colors from a colormap (e.g., viridis)\n",
    "original_cmap = cm.get_cmap('Reds')\n",
    "# cmap = cm.get_cmap('viridis_r')  # Choose any: 'viridis', 'coolwarm', 'inferno', etc.\n",
    "cmap = truncate_colormap(original_cmap, 0.15, 1.0) \n",
    "norm = mcolors.Normalize(vmin=edge_ratios['positive_ratio'].min(), vmax=edge_ratios['positive_ratio'].max())\n",
    "\n",
    "# Apply color to each edge based on positive_ratio\n",
    "for _, row in edge_ratios.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    ratio = row['positive_ratio']\n",
    "    color = mcolors.to_hex(cmap(norm(ratio)))  # Convert RGBA to HEX\n",
    "\n",
    "    d3.edge_properties.loc[\n",
    "        (d3.edge_properties['source'] == source) &\n",
    "        (d3.edge_properties['target'] == target),\n",
    "        'color'\n",
    "    ] = color\n",
    "\n",
    "# Show diagram\n",
    "d3.show()\n",
    "\n",
    "# %%\n",
    "fig, ax = plt.subplots(figsize=(0.5, 4))\n",
    "fig.subplots_adjust(left=0.4, right=0.9)\n",
    "\n",
    "# Create scalar mappable\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Explicitly provide the axis to use for the colorbar\n",
    "cbar = fig.colorbar(sm, cax=ax, orientation='vertical')\n",
    "cbar.set_label('Sample above legal limits', fontsize=12, labelpad=15)\n",
    "cbar.ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1.0, decimals=1))\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "plt.savefig(f'{tit}_legend.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_excel(\"original_sampling_country.xlsx\", \n",
    "                     sheet_name=\"yearly distribution\", index_col=0)\n",
    "positive_data = pd.read_excel(\"original_sampling_country.xlsx\", \n",
    "                              sheet_name=\"pos yearly distribution\", index_col=0)\n",
    "positive_data = positive_data.rename(columns={'number_of_samples': 'pos_number_of_samples'})\n",
    "# data = data.drop(data[data['year'] == 2107].index)\n",
    "data = data.drop(data[data['year'].isin([1970, 1998, 1999, 2107])].index)\n",
    "positive_data = positive_data.drop(positive_data[positive_data['year'].isin([1970, 1998, 1999, 2107])].index)\n",
    "\n",
    "#  Keep only the last 5 years\n",
    "latest_years = sorted(data['year'].unique())[-5:]  # Get last 5 years\n",
    "data = data[data['year'].isin(latest_years)]\n",
    "positive_data = positive_data[positive_data['year'].isin(latest_years)]\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = data.merge(positive_data, on=['orig_country', 'samp_country', 'year'], how='left')\n",
    "merged_data['pos_number_of_samples'] = merged_data['pos_number_of_samples'].fillna(0)\n",
    "\n",
    "# Sum across years for same (origin, sampling) country pairs\n",
    "merged_data = merged_data.groupby(['orig_country', 'samp_country'], as_index=False).agg({\n",
    "    'number_of_samples': 'sum',\n",
    "    'pos_number_of_samples': 'sum'\n",
    "})\n",
    "\n",
    "# Recalculate positive ratio after aggregation\n",
    "merged_data['positive_ratio'] = merged_data['pos_number_of_samples'] / merged_data['number_of_samples']\n",
    "\n",
    "merged_data['orig_country'] = merged_data['orig_country'].str.title()\n",
    "merged_data['samp_country'] = merged_data['samp_country'].str.title()\n",
    "\n",
    "\n",
    "\n",
    "# Assuming merged_data is already loaded and merged\n",
    "sample_counts = merged_data['number_of_samples']\n",
    "\n",
    "sample_cutoff = 100\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "top_n = 20\n",
    "ord = 'positive_ratio' #'positive_ratio' or \"number_of_samples\"\n",
    "\n",
    "# Filter data\n",
    "filtered_data = merged_data[\n",
    "    (merged_data['orig_country'] != merged_data['samp_country']) & \n",
    "    (merged_data['number_of_samples'] > sample_cutoff)\n",
    "]\n",
    "filtered_data = filtered_data.nlargest(top_n, ord)\n",
    "\n",
    "\n",
    "# Prepare chord diagram data\n",
    "chord_data = filtered_data[['orig_country', 'samp_country', 'number_of_samples']].copy()\n",
    "chord_data.columns = ['source', 'target', 'weight']  # Directly use D3Blocks' expected names\n",
    "\n",
    "\n",
    "\n",
    "tit = f\"Last3Years_chord_diag_top{top_n}count_top{sample_cutoff}samp_order{ord}\"\n",
    "\n",
    "# Store positive ratios for each edge\n",
    "edge_ratios = filtered_data[['orig_country', 'samp_country', 'positive_ratio']].copy()\n",
    "edge_ratios.columns = ['source', 'target', 'positive_ratio']\n",
    "\n",
    "# Create chord diagram\n",
    "d3 = D3Blocks()\n",
    "d3.chord(\n",
    "    chord_data,\n",
    "    filepath=f'{tit}.html',\n",
    "    title= tit,\n",
    "    figsize = [600,600],\n",
    "    fontsize=12,\n",
    "    arrowhead=20,\n",
    "    cmap='tab20',  # This applies to nodes only\n",
    "    notebook=False\n",
    ")\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=256):\n",
    "    \"\"\"Returns a truncated colormap from cmap between minval and maxval\"\"\"\n",
    "    new_cmap = LinearSegmentedColormap.from_list(\n",
    "        f'trunc({cmap.name},{minval:.2f},{maxval:.2f})',\n",
    "        cmap(np.linspace(minval, maxval, n))\n",
    "    )\n",
    "    return new_cmap\n",
    "\n",
    "# Normalize and map colors from a colormap (e.g., viridis)\n",
    "original_cmap = cm.get_cmap('Reds')\n",
    "# cmap = cm.get_cmap('viridis_r')  # Choose any: 'viridis', 'coolwarm', 'inferno', etc.\n",
    "cmap = truncate_colormap(original_cmap, 0.15, 1.0) \n",
    "norm = mcolors.Normalize(vmin=edge_ratios['positive_ratio'].min(), vmax=edge_ratios['positive_ratio'].max())\n",
    "\n",
    "# Apply color to each edge based on positive_ratio\n",
    "for _, row in edge_ratios.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    ratio = row['positive_ratio']\n",
    "    color = mcolors.to_hex(cmap(norm(ratio)))  # Convert RGBA to HEX\n",
    "\n",
    "    d3.edge_properties.loc[\n",
    "        (d3.edge_properties['source'] == source) &\n",
    "        (d3.edge_properties['target'] == target),\n",
    "        'color'\n",
    "    ] = color\n",
    "\n",
    "# Show diagram\n",
    "d3.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(0.5, 4))\n",
    "fig.subplots_adjust(left=0.4, right=0.9)\n",
    "\n",
    "# Create scalar mappable\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Explicitly provide the axis to use for the colorbar\n",
    "cbar = fig.colorbar(sm, cax=ax, orientation='vertical')\n",
    "cbar.set_label('Sample above legal limits', fontsize=12, labelpad=15)\n",
    "cbar.ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1.0, decimals=1))\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "plt.savefig(f'{tit}_legend.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_excel(\"original_sampling_country.xlsx\", \n",
    "                     sheet_name=\"yearly distribution\", index_col=0)\n",
    "positive_data = pd.read_excel(\"original_sampling_country.xlsx\", \n",
    "                              sheet_name=\"pos yearly distribution\", index_col=0)\n",
    "positive_data = positive_data.rename(columns={'number_of_samples': 'pos_number_of_samples'})\n",
    "data = data.drop(data[data['year'] == 2107].index)\n",
    "\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = data.merge(positive_data, on=['orig_country', 'samp_country', 'year'], how='left')\n",
    "merged_data['pos_number_of_samples'] = merged_data['pos_number_of_samples'].fillna(0)\n",
    "\n",
    "\n",
    "# Get total samples per year (this includes all years)\n",
    "total_samples_per_year = merged_data.groupby('year')['number_of_samples'].sum().reset_index()\n",
    "total_samples_per_year = total_samples_per_year.rename(columns={'number_of_samples': 'total_samples'})\n",
    "\n",
    "# Filter for unknown origin\n",
    "unknown_origin = merged_data[merged_data['orig_country'].str.lower() == 'unknown']\n",
    "\n",
    "# Get unknown samples per year\n",
    "unknown_samples_per_year = unknown_origin.groupby('year')['number_of_samples'].sum().reset_index()\n",
    "unknown_samples_per_year = unknown_samples_per_year.rename(columns={'number_of_samples': 'unknown_samples'})\n",
    "\n",
    "# Merge and fill missing unknown counts with 0\n",
    "percentages = total_samples_per_year.merge(unknown_samples_per_year, on='year', how='left')\n",
    "percentages['unknown_samples'] = percentages['unknown_samples'].fillna(0)\n",
    "\n",
    "# Calculate percentage\n",
    "percentages['unknown_percentage'] = (percentages['unknown_samples'] / percentages['total_samples']) * 100\n",
    "\n",
    "print(percentages)\n",
    "\n",
    "\n",
    "# Group by sampling country to see targets\n",
    "targets = unknown_origin.groupby('samp_country')['number_of_samples'].sum().reset_index()\n",
    "\n",
    "# Sort to see who was most frequently targeted\n",
    "targets = targets.sort_values(by='number_of_samples', ascending=False)\n",
    "\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample distribution with respect to number of positive measurements, and total measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of samples according to their number of positive measurements\n",
    "with PostgresDatabase(os.getenv(\"DB_HOST\"), os.getenv(\"DB_PORT\"), os.getenv(\"DB_NAME\"), os.getenv(\"DB_USERNAME\"), os.getenv(\"DB_PASSWORD\")) as db:\n",
    "    query = \"\"\"\n",
    "            SELECT positive_measurements, count(*) AS num_samples\n",
    "            FROM\n",
    "            (\n",
    "                SELECT sample_core_id, count(*) as positive_measurements\n",
    "                FROM (SELECT sample_core_id FROM efsa.measurement_core WHERE evalcode_id IN (2, 9, 11, 14)) AS t1\n",
    "                LEFT JOIN efsa.sample_core AS t2\n",
    "                    ON t1.sample_core_id=t2.id\n",
    "                GROUP BY t1.sample_core_id\n",
    "            )\n",
    "            GROUP BY positive_measurements\n",
    "            ORDER BY positive_measurements\n",
    "            \"\"\"\n",
    "    df = db.querydf(query)\n",
    "    df.to_excel(\"sample_distribution_wrt_positive_measurements.xlsx\", index=False)\n",
    "\n",
    "    query = \"\"\"\n",
    "            SELECT total_measurements, count(*) AS num_samples\n",
    "            FROM\n",
    "            (\n",
    "                SELECT sample_core_id, count(*) as total_measurements\n",
    "                FROM (SELECT sample_core_id FROM efsa.measurement_core) AS t1\n",
    "                LEFT JOIN efsa.sample_core AS t2\n",
    "                    ON t1.sample_core_id=t2.id\n",
    "                GROUP BY t1.sample_core_id\n",
    "            )\n",
    "            GROUP BY total_measurements\n",
    "            ORDER BY total_measurements\n",
    "            \"\"\"\n",
    "    df = db.querydf(query)\n",
    "    df.to_excel(\"sample_distribution_wrt_total_measurements.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_excel(\"sample_distribution_wrt_total_measurements.xlsx\")\n",
    "positive_data = pd.read_excel(\"sample_distribution_wrt_positive_measurements.xlsx\")\n",
    "\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create square plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6))  # Square: width == height\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(\n",
    "    x=\"total_measurements\",\n",
    "    y=\"num_samples\",\n",
    "    data=data,\n",
    "    color=\"tab:blue\",\n",
    "    s=15,\n",
    "    alpha=0.8,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "\n",
    "# Log scale for y-axis\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "# Titles and labels\n",
    "ax.set_title(\"Relationship Between Total Measurements and Number of Samples\", fontsize=14)\n",
    "ax.set_xlabel(\"Total Measurements\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of Samples (Log Scale)\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "ax.set_aspect(1.0 / ax.get_data_ratio(), adjustable='box')\n",
    "plt.savefig(\"samples_vs_measurements.png\", dpi=600, bbox_inches='tight')  # Save before plt.show()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
